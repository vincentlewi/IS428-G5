{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import catboost as cb\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt \n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor \n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_col_name(poi_name, col):\n",
    "    if col == \"hdb_lat\":\n",
    "        return \"LATITUDE\"\n",
    "    elif col == \"hdb_lon\":\n",
    "        return \"LONGITUDE\"\n",
    "    else:\n",
    "        return f\"{poi_name}_{col}\"\n",
    "\n",
    "inflation_rates = pd.read_csv(\"../datasets/hdb/inflation_rates.csv\", index_col='year')\n",
    "def calculate_inflation(price, year):\n",
    "    return price * inflation_rates.loc[year].values[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(min_year, max_year, selected_features=[]):\n",
    "    random.seed(42)\n",
    "    \n",
    "    # HDB transactions\n",
    "    hdb_trans = pd.read_csv(\"../datasets/hdb/hdb.csv\")\n",
    "    hdb_trans['year'] = pd.to_datetime(hdb_trans['month']).dt.year\n",
    "    hdb_trans = hdb_trans[(hdb_trans['year'] >= min_year) & (hdb_trans['year'] <= max_year)]\n",
    "    hdb_trans['remaining_lease'] = hdb_trans['lease_commence_date'] + 99 - hdb_trans['year']\n",
    "\n",
    "    # Calculate the inflation adjusted resale price\n",
    "    hdb_trans['resale_price'] = hdb_trans.apply(lambda x: calculate_inflation(x['resale_price'], x['year']), axis=1)\n",
    "\n",
    "    # Addresses to get the lat and lon of each transaction\n",
    "    addresses = pd.read_csv(\"../datasets/hdb/addresses.csv\")[['QUERY', 'LATITUDE', 'LONGITUDE']]\n",
    "    addresses[['LATITUDE', 'LONGITUDE']] = addresses[['LATITUDE', 'LONGITUDE']].round(5)\n",
    "    df = pd.merge(hdb_trans, addresses, left_on='address', right_on='QUERY', how='inner')\n",
    "\n",
    "    # Merge the poi data\n",
    "    for file in os.listdir(\"../datasets/poi/\"):\n",
    "        if \"hdb\" in file:\n",
    "            # Get the poi name\n",
    "            poi_name = file.split(\"_\")[0]\n",
    "            poi = pd.read_csv(f\"../datasets/poi/{file}\")\n",
    "\n",
    "            # Drop unnecessary columns\n",
    "            if 'Unnamed: 0' in poi.columns:\n",
    "                poi = poi.drop(columns=['Unnamed: 0', f'{poi_name}_lat', f'{poi_name}_lon'])\n",
    "            \n",
    "            # Rename the columns to differentiate between the different poi\n",
    "            poi.columns = [rename_col_name(poi_name, col) for col in poi.columns]\n",
    "            \n",
    "            # Round the lat and lon columns\n",
    "            poi[['LATITUDE', 'LONGITUDE']] = poi[['LATITUDE', 'LONGITUDE']].round(5)\n",
    "\n",
    "            # Merge the poi with the bus_counts\n",
    "            df = pd.merge(df, poi, on=['LATITUDE', 'LONGITUDE'])\n",
    "\n",
    "    # Drop the unnecessary columns\n",
    "    X = df.drop(columns=['resale_price', 'QUERY', 'LATITUDE', 'LONGITUDE', 'month', 'address', 'year', 'town', 'flat_type', 'lease_commence_date'])\n",
    "    y = df['resale_price']\n",
    "\n",
    "    # Drop the columns with high VIF\n",
    "    if selected_features:\n",
    "        X = X[selected_features]\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "X, y = get_data(2023, 2023)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           resale_price   R-squared:                       0.813\n",
      "Model:                            OLS   Adj. R-squared:                  0.813\n",
      "Method:                 Least Squares   F-statistic:                 1.117e+04\n",
      "Date:                Thu, 28 Mar 2024   Prob (F-statistic):               0.00\n",
      "Time:                        21:42:13   Log-Likelihood:            -3.2469e+05\n",
      "No. Observations:               25672   AIC:                         6.494e+05\n",
      "Df Residuals:                   25661   BIC:                         6.495e+05\n",
      "Df Model:                          10                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==========================================================================================\n",
      "                             coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------------\n",
      "const                  -1.073e+05   3754.066    -28.591      0.000   -1.15e+05      -1e+05\n",
      "floor_area_sqm          5756.3921     20.750    277.414      0.000    5715.721    5797.064\n",
      "remaining_lease         5718.6964     33.427    171.082      0.000    5653.178    5784.215\n",
      "bus_within_0.5           852.5080    108.545      7.854      0.000     639.754    1065.262\n",
      "cbd_distance           -1.855e+04    135.846   -136.538      0.000   -1.88e+04   -1.83e+04\n",
      "hawker_distance        -2.751e+04   1021.381    -26.935      0.000   -2.95e+04   -2.55e+04\n",
      "mall_within_2.0         -714.2670    175.599     -4.068      0.000   -1058.451    -370.083\n",
      "mrtlrt_distance        -2.727e+04   1350.345    -20.194      0.000   -2.99e+04   -2.46e+04\n",
      "park_distance          -1.283e+04   1175.297    -10.914      0.000   -1.51e+04   -1.05e+04\n",
      "school_within_2.0      -2184.6524     99.570    -21.941      0.000   -2379.815   -1989.489\n",
      "supermarket_within_0.5  7269.0895    378.522     19.204      0.000    6527.166    8011.013\n",
      "==============================================================================\n",
      "Omnibus:                     5538.816   Durbin-Watson:                   0.998\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            19785.004\n",
      "Skew:                           1.062   Prob(JB):                         0.00\n",
      "Kurtosis:                       6.740   Cond. No.                     1.01e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.01e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "sel_X = X.copy()\n",
    "sel_X = sm.add_constant(sel_X)\n",
    "sel_X = sel_X.drop(columns=['bus_distance',\n",
    "                            'bus_within_0.1',\n",
    "                            'bus_within_0.3',\n",
    "                            'bus_within_1',\n",
    "                            'bus_within_1.5',\n",
    "                            'bus_within_2.0',\n",
    "                            'mrtlrt_within_0.1',\n",
    "                            'mrtlrt_within_0.3',\n",
    "                            'mrtlrt_within_0.5',\n",
    "                            'mrtlrt_within_1',\n",
    "                            'mrtlrt_within_1.5',\n",
    "                            'mrtlrt_within_2.0',\n",
    "                            'mrtlrt_within_2.0',\n",
    "                            'hawker_within_0.1',\n",
    "                            'hawker_within_0.3',\n",
    "                            'hawker_within_0.5',\n",
    "                            'hawker_within_1',\n",
    "                            'hawker_within_1.5',\n",
    "                            'hawker_within_2.0',\n",
    "                            'park_within_0.1',\n",
    "                            'park_within_0.3',\n",
    "                            'park_within_0.5',\n",
    "                            'park_within_1',\n",
    "                            'park_within_1.5',\n",
    "                            'park_within_2.0',\n",
    "                            'school_distance',\n",
    "                            'school_within_0.1',\n",
    "                            'school_within_0.3',\n",
    "                            'school_within_0.5',\n",
    "                            'school_within_1',\n",
    "                            'school_within_1.5',\n",
    "                            'supermarket_within_0.1',\n",
    "                            'supermarket_within_0.3',\n",
    "                            'supermarket_distance',\n",
    "                            'supermarket_within_1',\n",
    "                            'supermarket_within_1.5',\n",
    "                            'supermarket_within_2.0',\n",
    "                            'mall_distance',\n",
    "                            'mall_within_0.1',\n",
    "                            'mall_within_0.3',\n",
    "                            'mall_within_0.5',\n",
    "                            'mall_within_1',\n",
    "                            'mall_within_1.5',])\n",
    "\n",
    "est = sm.OLS(y, sel_X)\n",
    "est2 = est.fit()\n",
    "print(est2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array(['const', 63.86820329694119], dtype=object), array(['cbd_distance', 1.5726501567707694], dtype=object)]\n",
      "                   feature        VIF\n",
      "0                    const  63.868203\n",
      "1           floor_area_sqm   1.084644\n",
      "2          remaining_lease   1.151178\n",
      "3           bus_within_0.5   1.152116\n",
      "4             cbd_distance   1.572650\n",
      "5          hawker_distance   1.249053\n",
      "6          mall_within_2.0   1.168380\n",
      "7          mrtlrt_distance   1.168250\n",
      "8            park_distance   1.208653\n",
      "9        school_within_2.0   1.204286\n",
      "10  supermarket_within_0.5   1.095550\n"
     ]
    }
   ],
   "source": [
    "vif_df = sel_X.copy().drop(columns=[])\n",
    "\n",
    "# VIF dataframe \n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"feature\"] = vif_df.columns \n",
    "\n",
    "# calculating VIF for each feature \n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(vif_df.values, i) \n",
    "                          for i in range(len(vif_df.columns))] \n",
    "  \n",
    "print(sorted(vif_data.values, key=lambda x: x[1], reverse=True)[0:2])\n",
    "print(vif_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = vif_data[vif_data['VIF'] < 5]['feature'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdb_available, resale_price = get_data(2017, 2022, selected_features=selected_features)\n",
    "hdb_available['resale_price'] = resale_price\n",
    "hdb_available.to_csv(\"../src/assets/datasets/hdb/hdb_available.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Catboost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize grid\n",
    "grid = {'iterations': [500, 750, 1000],\n",
    "        'depth': [14, 16],\n",
    "        'l2_leaf_reg': [0.2, 0.3, 0.5]}\n",
    "\n",
    "def train(min_year, max_year):\n",
    "    print(f\"Training model for year {min_year}-{max_year}\")\n",
    "\n",
    "    # Get the data\n",
    "    X, y = get_data(min_year, max_year, selected_features)\n",
    "    dataset = cb.Pool(X, y)\n",
    "#     model = cb.CatBoostRegressor(iterations=500,\n",
    "#                                   depth=16,\n",
    "#                                   l2_leaf_reg=0.3,\n",
    "#                                   loss_function=\"RMSE\", \n",
    "#                                   logging_level='Silent',\n",
    "#                                   task_type=\"GPU\",\n",
    "#                                   devices='0')\n",
    "    \n",
    "#     # Fit the model\n",
    "#     model.fit(dataset)\n",
    "    \n",
    "    model = cb.CatBoostRegressor(loss_function=\"RMSE\",\n",
    "                                 logging_level='Silent',\n",
    "                                 task_type=\"GPU\",\n",
    "                                 devices='0')\n",
    "    \n",
    "    model.grid_search(grid, dataset, cv=5, partition_random_seed=42)\n",
    "\n",
    "    # Evaluate the model\n",
    "    pred = model.predict(X)\n",
    "    mape = mean_absolute_percentage_error(y, pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y, pred))\n",
    "    r2 = r2_score(y, pred)\n",
    "    print(f\"Testing performance for year {min_year}-{max_year}:\")\n",
    "    print(f'MAPE: {mape:.2%}')\n",
    "    print(f'RMSE: {rmse:.2f}')\n",
    "    print(f'R2: {r2:.2f}')\n",
    "\n",
    "    # Save the feature importances\n",
    "    features_df = model.get_feature_importance(prettified=True)\n",
    "    features_df.to_csv(f\"./feature_importances/catboost_{min_year}_{max_year}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for year 2000-2003\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "CatBoost.grid_search() got an unexpected keyword argument 'use_best_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m min_year \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2020\u001b[39m:\n\u001b[0;32m      4\u001b[0m     max_year \u001b[38;5;241m=\u001b[39m max_year \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m----> 6\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmin_year\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_year\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[7], line 28\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(min_year, max_year)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m#     model = cb.CatBoostRegressor(iterations=500,\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m#                                   depth=16,\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m#                                   l2_leaf_reg=0.3,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m#     # Fit the model\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m#     model.fit(dataset)\u001b[39;00m\n\u001b[0;32m     23\u001b[0m     model \u001b[38;5;241m=\u001b[39m cb\u001b[38;5;241m.\u001b[39mCatBoostRegressor(loss_function\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRMSE\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     24\u001b[0m                                  logging_level\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSilent\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     25\u001b[0m                                  task_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGPU\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     26\u001b[0m                                  devices\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 28\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrid_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartition_random_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_best_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[0;32m     31\u001b[0m     pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X)\n",
      "\u001b[1;31mTypeError\u001b[0m: CatBoost.grid_search() got an unexpected keyword argument 'use_best_model'"
     ]
    }
   ],
   "source": [
    "for min_year in range(2000, 2024, 4):\n",
    "    max_year = min_year + 3\n",
    "    if min_year == 2020:\n",
    "        max_year = max_year + 1\n",
    "    \n",
    "    train(min_year, max_year)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
