{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import catboost as cb\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Import\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_col_name(poi_name, col):\n",
    "    if col == \"hdb_lat\":\n",
    "        return \"LATITUDE\"\n",
    "    elif col == \"hdb_lon\":\n",
    "        return \"LONGITUDE\"\n",
    "    else:\n",
    "        return f\"{poi_name}_{col}\"\n",
    "\n",
    "\n",
    "inflation_rates = pd.read_csv(\"../datasets/hdb/inflation_rates.csv\", index_col=\"year\")\n",
    "\n",
    "\n",
    "def calculate_inflation(price, year):\n",
    "    return price * inflation_rates.loc[year].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(min_year, max_year, selected_features=[]):\n",
    "    random.seed(42)\n",
    "\n",
    "    # HDB transactions\n",
    "    hdb_trans = pd.read_csv(\"../datasets/hdb/hdb.csv\")\n",
    "    hdb_trans[\"year\"] = pd.to_datetime(hdb_trans[\"month\"]).dt.year\n",
    "    hdb_trans = hdb_trans[\n",
    "        (hdb_trans[\"year\"] >= min_year) & (hdb_trans[\"year\"] <= max_year)\n",
    "    ]\n",
    "    hdb_trans[\"remaining_lease\"] = (\n",
    "        hdb_trans[\"lease_commence_date\"] + 99 - hdb_trans[\"year\"]\n",
    "    )\n",
    "\n",
    "    # Calculate the inflation adjusted resale price\n",
    "    hdb_trans[\"resale_price\"] = hdb_trans.apply(\n",
    "        lambda x: calculate_inflation(x[\"resale_price\"], x[\"year\"]), axis=1\n",
    "    )\n",
    "\n",
    "    # Addresses to get the lat and lon of each transaction\n",
    "    addresses = pd.read_csv(\"../datasets/hdb/addresses.csv\")[\n",
    "        [\"QUERY\", \"LATITUDE\", \"LONGITUDE\"]\n",
    "    ]\n",
    "    addresses[[\"LATITUDE\", \"LONGITUDE\"]] = addresses[[\"LATITUDE\", \"LONGITUDE\"]].round(5)\n",
    "    df = pd.merge(\n",
    "        hdb_trans, addresses, left_on=\"address\", right_on=\"QUERY\", how=\"inner\"\n",
    "    )\n",
    "\n",
    "    # Merge the poi data\n",
    "    for file in os.listdir(\"../datasets/poi/\"):\n",
    "        if \"hdb\" in file:\n",
    "            # Get the poi name\n",
    "            poi_name = file.split(\"_\")[0]\n",
    "            poi = pd.read_csv(f\"../datasets/poi/{file}\")\n",
    "\n",
    "            # Drop unnecessary columns\n",
    "            if \"Unnamed: 0\" in poi.columns:\n",
    "                poi = poi.drop(\n",
    "                    columns=[\"Unnamed: 0\", f\"{poi_name}_lat\", f\"{poi_name}_lon\"]\n",
    "                )\n",
    "\n",
    "            # Rename the columns to differentiate between the different poi\n",
    "            poi.columns = [rename_col_name(poi_name, col) for col in poi.columns]\n",
    "\n",
    "            # Round the lat and lon columns\n",
    "            poi[[\"LATITUDE\", \"LONGITUDE\"]] = poi[[\"LATITUDE\", \"LONGITUDE\"]].round(5)\n",
    "\n",
    "            # Merge the poi with the bus_counts\n",
    "            df = pd.merge(df, poi, on=[\"LATITUDE\", \"LONGITUDE\"])\n",
    "\n",
    "    # Drop the unnecessary columns\n",
    "    X = df.drop(\n",
    "        columns=[\n",
    "            \"resale_price\",\n",
    "            \"QUERY\",\n",
    "            \"LATITUDE\",\n",
    "            \"LONGITUDE\",\n",
    "            \"month\",\n",
    "            \"address\",\n",
    "            \"year\",\n",
    "            \"town\",\n",
    "            \"flat_type\",\n",
    "            \"lease_commence_date\",\n",
    "        ]\n",
    "    )\n",
    "    y = df[\"resale_price\"]\n",
    "\n",
    "    # Drop the columns with high VIF\n",
    "    if selected_features:\n",
    "        X = X[selected_features]\n",
    "\n",
    "    return X, y\n",
    "\n",
    "\n",
    "X, y = get_data(2023, 2023)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           resale_price   R-squared:                       0.813\n",
      "Model:                            OLS   Adj. R-squared:                  0.813\n",
      "Method:                 Least Squares   F-statistic:                 1.117e+04\n",
      "Date:                Thu, 28 Mar 2024   Prob (F-statistic):               0.00\n",
      "Time:                        21:42:13   Log-Likelihood:            -3.2469e+05\n",
      "No. Observations:               25672   AIC:                         6.494e+05\n",
      "Df Residuals:                   25661   BIC:                         6.495e+05\n",
      "Df Model:                          10                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==========================================================================================\n",
      "                             coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------------\n",
      "const                  -1.073e+05   3754.066    -28.591      0.000   -1.15e+05      -1e+05\n",
      "floor_area_sqm          5756.3921     20.750    277.414      0.000    5715.721    5797.064\n",
      "remaining_lease         5718.6964     33.427    171.082      0.000    5653.178    5784.215\n",
      "bus_within_0.5           852.5080    108.545      7.854      0.000     639.754    1065.262\n",
      "cbd_distance           -1.855e+04    135.846   -136.538      0.000   -1.88e+04   -1.83e+04\n",
      "hawker_distance        -2.751e+04   1021.381    -26.935      0.000   -2.95e+04   -2.55e+04\n",
      "mall_within_2.0         -714.2670    175.599     -4.068      0.000   -1058.451    -370.083\n",
      "mrtlrt_distance        -2.727e+04   1350.345    -20.194      0.000   -2.99e+04   -2.46e+04\n",
      "park_distance          -1.283e+04   1175.297    -10.914      0.000   -1.51e+04   -1.05e+04\n",
      "school_within_2.0      -2184.6524     99.570    -21.941      0.000   -2379.815   -1989.489\n",
      "supermarket_within_0.5  7269.0895    378.522     19.204      0.000    6527.166    8011.013\n",
      "==============================================================================\n",
      "Omnibus:                     5538.816   Durbin-Watson:                   0.998\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            19785.004\n",
      "Skew:                           1.062   Prob(JB):                         0.00\n",
      "Kurtosis:                       6.740   Cond. No.                     1.01e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.01e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "sel_X = X.copy()\n",
    "sel_X = sm.add_constant(sel_X)\n",
    "sel_X = sel_X.drop(\n",
    "    columns=[\n",
    "        \"bus_distance\",\n",
    "        \"bus_within_0.1\",\n",
    "        \"bus_within_0.3\",\n",
    "        \"bus_within_1\",\n",
    "        \"bus_within_1.5\",\n",
    "        \"bus_within_2.0\",\n",
    "        \"mrtlrt_within_0.1\",\n",
    "        \"mrtlrt_within_0.3\",\n",
    "        \"mrtlrt_within_0.5\",\n",
    "        \"mrtlrt_within_1\",\n",
    "        \"mrtlrt_within_1.5\",\n",
    "        \"mrtlrt_within_2.0\",\n",
    "        \"mrtlrt_within_2.0\",\n",
    "        \"hawker_within_0.1\",\n",
    "        \"hawker_within_0.3\",\n",
    "        \"hawker_within_0.5\",\n",
    "        \"hawker_within_1\",\n",
    "        \"hawker_within_1.5\",\n",
    "        \"hawker_within_2.0\",\n",
    "        \"park_within_0.1\",\n",
    "        \"park_within_0.3\",\n",
    "        \"park_within_0.5\",\n",
    "        \"park_within_1\",\n",
    "        \"park_within_1.5\",\n",
    "        \"park_within_2.0\",\n",
    "        \"school_distance\",\n",
    "        \"school_within_0.1\",\n",
    "        \"school_within_0.3\",\n",
    "        \"school_within_0.5\",\n",
    "        \"school_within_1\",\n",
    "        \"school_within_1.5\",\n",
    "        \"supermarket_within_0.1\",\n",
    "        \"supermarket_within_0.3\",\n",
    "        \"supermarket_distance\",\n",
    "        \"supermarket_within_1\",\n",
    "        \"supermarket_within_1.5\",\n",
    "        \"supermarket_within_2.0\",\n",
    "        \"mall_distance\",\n",
    "        \"mall_within_0.1\",\n",
    "        \"mall_within_0.3\",\n",
    "        \"mall_within_0.5\",\n",
    "        \"mall_within_1\",\n",
    "        \"mall_within_1.5\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "est = sm.OLS(y, sel_X)\n",
    "est2 = est.fit()\n",
    "print(est2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array(['const', 63.86820329694119], dtype=object), array(['cbd_distance', 1.5726501567707694], dtype=object)]\n",
      "                   feature        VIF\n",
      "0                    const  63.868203\n",
      "1           floor_area_sqm   1.084644\n",
      "2          remaining_lease   1.151178\n",
      "3           bus_within_0.5   1.152116\n",
      "4             cbd_distance   1.572650\n",
      "5          hawker_distance   1.249053\n",
      "6          mall_within_2.0   1.168380\n",
      "7          mrtlrt_distance   1.168250\n",
      "8            park_distance   1.208653\n",
      "9        school_within_2.0   1.204286\n",
      "10  supermarket_within_0.5   1.095550\n"
     ]
    }
   ],
   "source": [
    "vif_df = sel_X.copy().drop(columns=[])\n",
    "\n",
    "# VIF dataframe\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"feature\"] = vif_df.columns\n",
    "\n",
    "# calculating VIF for each feature\n",
    "vif_data[\"VIF\"] = [\n",
    "    variance_inflation_factor(vif_df.values, i) for i in range(len(vif_df.columns))\n",
    "]\n",
    "\n",
    "print(sorted(vif_data.values, key=lambda x: x[1], reverse=True)[0:2])\n",
    "print(vif_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = vif_data[vif_data[\"VIF\"] < 5][\"feature\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdb_available, resale_price = get_data(2017, 2022, selected_features=selected_features)\n",
    "hdb_available[\"resale_price\"] = resale_price\n",
    "hdb_available.to_csv(\"../src/assets/datasets/hdb/hdb_available.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Catboost Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize grid\n",
    "grid = {\n",
    "    \"iterations\": [500, 750, 1000],\n",
    "    \"depth\": [14, 16],\n",
    "    \"l2_leaf_reg\": [0.2, 0.3, 0.5],\n",
    "}\n",
    "\n",
    "\n",
    "def train(min_year, max_year):\n",
    "    print(f\"Training model for year {min_year}-{max_year}\")\n",
    "\n",
    "    # Get the data\n",
    "    X, y = get_data(min_year, max_year, selected_features)\n",
    "    dataset = cb.Pool(X, y)\n",
    "    #     model = cb.CatBoostRegressor(iterations=500,\n",
    "    #                                   depth=16,\n",
    "    #                                   l2_leaf_reg=0.3,\n",
    "    #                                   loss_function=\"RMSE\",\n",
    "    #                                   logging_level='Silent',\n",
    "    #                                   task_type=\"GPU\",\n",
    "    #                                   devices='0')\n",
    "\n",
    "    #     # Fit the model\n",
    "    #     model.fit(dataset)\n",
    "\n",
    "    model = cb.CatBoostRegressor(\n",
    "        loss_function=\"RMSE\", logging_level=\"Silent\", task_type=\"GPU\", devices=\"0\"\n",
    "    )\n",
    "\n",
    "    model.grid_search(grid, dataset, cv=5, partition_random_seed=42)\n",
    "\n",
    "    # Evaluate the model\n",
    "    pred = model.predict(X)\n",
    "    mape = mean_absolute_percentage_error(y, pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y, pred))\n",
    "    r2 = r2_score(y, pred)\n",
    "    print(f\"Testing performance for year {min_year}-{max_year}:\")\n",
    "    print(f\"MAPE: {mape:.2%}\")\n",
    "    print(f\"RMSE: {rmse:.2f}\")\n",
    "    print(f\"R2: {r2:.2f}\")\n",
    "\n",
    "    # Save the feature importances\n",
    "    features_df = model.get_feature_importance(prettified=True)\n",
    "    features_df.to_csv(f\"./feature_importances/catboost_{min_year}_{max_year}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for min_year in range(2000, 2024, 4):\n",
    "    max_year = min_year + 3\n",
    "    if min_year == 2020:\n",
    "        max_year = max_year + 1\n",
    "\n",
    "    train(min_year, max_year)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
